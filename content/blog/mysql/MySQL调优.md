### 1、如何写出高性能SQL语句



#### 慢SQL语句的几种常见诱因

> 1、无索引、索引失效导致慢查询



> 2、锁等待

我们常见的存储引擎有InnoDB和MyISAM，前者支持行锁和表锁，后者只支持表锁。

MySQL认为如果对一张表使用大量的行锁，会导致事务执行效率下降，从而可能造成其他事务长时间锁等待和更多的锁冲突问题发生，致使性能严重下降，所以MySQL会将行锁升级为表锁。还有，行锁基于索引加的锁，如果我们在更新操作时，条件索引失效，那么行锁也会升级为表锁。

因此，基于表锁的数据库操作，会导致SQL阻塞等待，从而影响执行速度，在一些更新操作(insert\update\delete)大于或等于读操作的情况下，MySQL不建议使用MyISAM存储引擎。

> 3、不恰当的SQL语句



#### 优化SQL语句步骤

1、通过Explain分析SQL执行计划

假设现在我们使用Explain命令查看当前SQL是否使用了索引，先通过SQL Explain到处相应的执行计划如下：

<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318102146813.png" alt="image-20210318102146813" style="zoom:67%;" />![image-20210318102353063](/Users/lichai/Library/Application Support/typora-user-images/image-20210318102353063.png)



<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318102535648.png" alt="image-20210318102535648" style="zoom:67%;" />

- ALL：表示全表扫描，需要遍历全表来找到对应的行。
- Possible_keys：可能使用到的索引
- Key：当前使用的索引的长度
- key_len：当前使用的索引的长度。
- Ref：关联id等信息
- Rows：查找到记录所描述的行数
- Filtered：查找到所需记录占总扫描记录数的比例
- Extra：额外的信息





### 2、高并发场景下数据库事务调优



数据库事务是数据库系统执行过程中一个逻辑处理单元，保证一个数据库操作要么成功，要么失败。数据库事务具有以下四个基本属性：原子性、一致性、隔离性、持久性。正是这些特性，才保证了数据事务的安全性。



#### 并发事务带来的问题



我们可以通过以下几个例子来了解并发事务带来的几个问题

<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210317180946325.png" alt="image-20210317180946325" style="zoom:67%;" />

<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210317181039820.png" alt="image-20210317181039820" style="zoom:67%;" />

#### 事务隔离解决并发问题



以上4个并发事务带来的问题，其中，数据丢失可以基于数据库中的悲观锁来避免发生，即在查询时通过在事务中使用select xx for update语句来实现一个排他锁，保证该事务结束之前其他事务无法更新该数据。

当然，我们也可以基于乐观锁来避免，即将某一字段作为版本号，如果更新时的版本号跟之前的版本一致，则更新，否则更新失败。剩下3个问题，其实是数据库读一致性造成的，需要数据库提供一定的事务隔离机制来解决。

我们通过加锁的方式，可以实现不同的事务隔离机制。

InnoDB实现了两种类型的锁机制：共享锁(S)和排他锁(X)。共享锁允许一个事务读数据，不允许修改数据，如果其他事务要再对该行加锁，只能加共享锁；排他锁是修改数据时加的锁，可以读取和修改数据，一旦一个事务对该行数据加锁，其他事务将不再对该数据加任何锁。

在操作数据的事务中，不同的锁机制会产生以下几种不同的事务隔离级别，不同的隔离级别分别可以解决并发事务产生的几个问题，对应如下：

未提交读(Read Uncommitted)：在事务A读取数据时，事务B读取和修改数据加了共享锁。这种隔离级别，会导致脏读、不可重复读以及幻读。

已提交读(Read committed)：在事务A读取数据时增加了共享锁，一旦读取，立即释放锁，事务B读取修改数据时增加了行级排他锁，直到事务结束才释放锁。也就是说，事务A在读取数据时，事务B只能读取数据，不能修改，当事务A读取到数据后，事务B才能修改。这种隔离级别，可以避免脏读，但依然存在不可重复读以及幻读的问题。

可重复读(Repeatable Read)：在事务A读取数据时增加了共享锁，事务结束，才释放锁，事务B读取修改数据时增加了行级排他锁，直到事务结束后才释放锁。也就是说， 事务A在没有结束事务时，事务B只能读取数据，不能修改。当事务A结束事务，事务B才能修改，这种隔离级别，可以避免脏读、不可重复读，但依然存在幻读的问题。

可序列化(Serializable)：在事务A读取数据时增加了共享锁，事务结束，才释放锁，事务B读取修改数据时增加了表级排他锁，直到事务结束才释放锁。可序列化解决了脏读、不可重复读、幻读等问题，但隔离级别越来越高的同时，并发性会越来越低。

InnoDB中的RC和RR隔离级别是基于多版本并发控制(MVCC)，实现高性能事务，一旦数据被加上排他锁，其他事务将无法加入共享锁，且处于阻塞等待状态，如果一张表有大量的请求，这样的性能将无法支持的。

MVCC对普通的select不加锁，如果读取的数据正在执行delete或update操作，这时读取操作不会等待排它锁的释放，而是直接利用MVCC读取该行的数据快照(数据快照是指在该行的之前版本的数据，而数据快照的版本是基于undo实现的，undo是用来做事务回滚的，记录了回滚的不同版本的行记录)。MVCC避免了对数据重复加锁的过程，大大提高了读操作的性能。



#### 锁具体实现算法

我们知道，InnoDB即实现了行锁，也实现了表锁，行锁是通过索引实现的，如果不通过索引条件检索数据，那么InnoDB将对表中所有的记录进行加锁，其实就是升级为表锁了。

行锁的具体实现算法有三种：record lock、gap lock以及next-key lock。record lock是专门对索引项加锁，gap lock是对索引项之间的间隙加锁，next-key lock则是前面两种的组合，对索引项以及之间的间隙加锁。

只有可重复读或以上隔离级别下的特定操作才会取得gap lock或next-key lock，在select、update和delete时，除了基于唯一索引的查询之外，其他索引查询时都会获取gap lock或next-key lock，即锁住其扫描的范围。



#### 优化高并发事务

1、结合业务场景，使用低级别事务隔离

2、避免行锁升级表锁

3、控制事务的大小，减少锁定的资源量和锁定时间长度



### 3、索引的失效与优化



#### MySQL索引存储结构

索引是优化数据库查询最重要的方式之一，它是在MySQL的存储引擎层中实现的，所以每一种存储引擎对应的索引不一定相同。

<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318134115687.png" alt="image-20210318134115687" style="zoom:67%;" />

B+Tree索引和Hash索引是我们比较常用的两个索引数据存储结构，B+Tree索引是通过B+树实现的，是有序排列存储，所以在排序和范围查找方面都比较有优势。

Hash索引相对简单些，只有Memory存储引擎支持Hash索引。Hash索引适合key-value键值对查询，无论表数据多大，查询数据的复杂度都是O(1)，且直接通过Hash索引查询的性能比其它索引都要优越。

在创建表时，无论使用InnoDB还是MyISAM存储引擎，默认都会创建一个主键索引，而创建的主键索引默认使用的是B+Tree索引。不过虽然这两个存储引擎都支持B+Tree索引，但他们在具体的数据存储结构方面却有所不同。

InnoDB默认创建的主键索引是聚簇索引，也被称为二级索引或非聚簇索引。

如果我们使用的事MyISAM存储引擎，由于MyISAM使用的事辅助索引，索引中每一个叶子节点仅仅记录的事每行数据的物理地址，即行指针

<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318140830520.png" alt="image-20210318140830520" style="zoom:67%;" />

如果我们使用的是InnoDB存储引擎，由于InnoDB使用的事聚族索引，聚族索引中的叶子节点则记录了主键值、事务id、用于事务和MVCC的回流指针以及所有的剩余列。

<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318141008153.png" alt="image-20210318141008153" style="zoom:67%;" />

基于上面的图示，如果我们需要根据商品编码查询商品，我们就需要将商品编码serial_no列作为一个索引列。此时创建的索引是一个辅助索引，与MyISAM存储引擎的主键索引的存储方式是一致的，但叶子节点存储的就不是行指针了，而是主键值，并以此作为指向行的指针。这样的好处就是当行发生移动或者数据分裂时，不用再维护索引的变更。

我们使用商品编码查询商品，即使用辅助索引进行查询，则会先检索辅助索引中的B+树的serial_no，找到对应的叶子节点，获取主键值，然后在通过聚族索引中的B+树检索到对应的叶子节点，然后获取整行数据。这个过程叫做回表。



##### 1、覆盖索引优化查询

假设我们只需要查询商品的名称、价格信息，我们有什么方式来避免回表呢？我们可以建立一个组合索引，即商品编码、名称、价格作为一个组合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表。

从辅助索引中查询得到记录，而不需要通过聚族索引查询获得，MySQL中将其称为覆盖索引。

##### 2、自增字段作为主键优化查询

如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为不需要重新移动数据，因此这种插入数据的方法效率非常高。

##### 3、前缀索引优化

使用某个字段中的前几个字符建立索引。

不过，前缀索引是有一定的局限性的，例如order by就无法使用前缀索引，无法把前缀索引用作覆盖索引。

##### 4、防止索引失效



### SQL死锁事故：如何避免死锁



<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318143341016.png" alt="image-20210318143341016" style="zoom:50%;" />



<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318143353951.png" alt="image-20210318143353951" style="zoom:50%;" />



看到这，你可能会想，为什么select要加for update排他锁，而不是共享锁呢？试想下，如果两个订单号一样的请求同时过来，就有可能出现幻读。也就是说，一开始事务A中的查询没有该订单号，后来事务B新增了一个该订单号的记录，此时事务A在新增一条该订单号数据，就会创建重复的订单记录。面对这种情况，我们可以使用锁间隙算法来防止幻读。



在MySQL中，gap lock默认是开启的，即innodb_locks_unsafe_for_binlog参数值是disable的，且MySQL中默认的是RR事务隔离级别的。

当我们执行以下查询SQL时，由于order_no列为非唯一索引，此时又是RR事务隔离级别，所以SELECT的加锁类型为gap lock，这里的gap范围就是(4, 无穷)

> Select id from demo.order_record where order_no = 4 for update

执行查询SQL语句获取的gap lock并不会导致阻塞，而当我们执行以下插入SQL时，会在插入间隙再次获取插入意向锁。插入意向锁其实也是一种gap锁，它与gap lock是冲突的，所以当其它事务持有该间隙的gap lock时，需要等待其它事务释放gap lock之后，才能获取到插入意向锁。

以上事务A和事务B都持有间隙(4, 无穷)的gap锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的gap锁释放，于是就造成了循环等待，导致死锁。



#### 避免死锁的措施

避免死锁最直观的方法就是两个事务相互等待时，当一个事务的等待时间超过设置的某一阈值，就对这个事务进行回滚，另一个事务就可以继续执行了，这种方法简单有效，在InnoDB中，参数innodb_lock_wait_timeout是用来设置超时时间的。

另外，我们可以将order_no列设置为唯一索引列。虽然不能防止幻读，但我们可以利用它的唯一性来保证订单记录不重复创建，这种方式唯一缺点就是当遇到重复创建订单时会抛出异常。

我们还可以使用其他的方式来代替数据实现幂等性校验，例如，使用Redis以及ZooKeeper来实现，运行效率比数据库更佳。



死锁的四个必要条件：

- 互斥
- 占有且等待
- 不可强占用
- 循环

<img src="/Users/lichai/Library/Application Support/typora-user-images/image-20210318145940827.png" alt="image-20210318145940827" style="zoom:50%;" />

解决死锁的最佳方式当然就是预防死锁的发生了，我们平时编程中，可以通过以下一些常规手段来预防死锁的发生：

1、编程中尽量按照固定的顺序来处理数据库记录，假设有两个更新操作，分别更新两条相同的记录，但更新顺序不一样，有可能导致死锁。

2、在允许幻读和不可重复读的情况下，尽量使用RC事务隔离级别，可以避免gap lock导致的死锁问题

3、更新表时，尽量使用主键更新

4、避免长事务，尽量将长事务拆解，可以降低与其他事务发生冲突的概率

5、设置锁等待超时参数，我们可以通过innodb_lock_wait_timeout设置合理的等待超时阈值，特别是在一些高并发的业务中，我们可以尽量将该值设置的小一些，避免大量事务等待，占用系统资源，造成严重的性能开销。

### InnoDB事务之redo log工作原理

InnoDB是一个事务性的存储引擎，而InnoDB的事务实现是基于事务日志redo log和undo log实现的。redo log是重做日志，提供在写入操作，实现事务的持久性；undo log是回滚日志，提供回滚操作，保证事务的一致性。

Redo log又包括了内存中的日志缓冲(redo log buffer)以及保存在磁盘的重做日志文件(redo log file)，前者存储在内存中，容易丢失，后者持久化在磁盘中，不会丢失。

InnoDB的更新操作采用的事Write Ahead Log策略，即先写日志，在写入磁盘。当一条记录更新时，InnoDb会先把记录写入到redo log buffer中，病更新内存新数据。我们可以通过参数innodb_flush_log_at_trx_commit自定义commit时，如何将redo log buffer中的日志刷新到redo log file中。

在这里，我们需要注意的是InnoDB的redo log的大小是固定的，分别有多个日志文件采用循环方式组成一个循环闭环，当写到结尾时，会回到开头循环写日志，我们可以通过参数配置日志文件数量和每个日志文件的大小。

Buffer Pool中更新的数据未刷新到磁盘中，该内存页我们称之为脏页。最终脏页的数据会刷新到磁盘中，将磁盘中的数据覆盖

只有当redo log日志满了的情况下，才会主动触发脏页刷新到磁盘，而脏页不仅只有redo log日志满了的情况才会刷新到磁盘，以下几种情况同样会触发脏页刷新：

- 系统内存不足时，需要将一部分数据页淘汰掉，如果淘汰的事脏页，需要先将脏页同步到磁盘；
- MySQL认为空闲的时间，这种情况没有性能问题
- MySQL正常关闭之前，会把所有的脏页刷入到磁盘，这种情况也没有性能问题



















